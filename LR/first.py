import pandas as pd
import os
import optuna
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.impute import SimpleImputer
import numpy as np
import json

# ğŸ“ è³‡æ–™å¤¾è·¯å¾‘
data_dir = "../database"
output_dir = "../database/lr_results"
imputed_dir = "../database/imputed_data"
os.makedirs(output_dir, exist_ok=True)
os.makedirs(imputed_dir, exist_ok=True)

# ğŸ“Œ é‡å°æ¯å€‹ CSV æª”æ¡ˆè·‘ Optuna + LR
for i in range(1, 17):
    file_path = os.path.normpath(os.path.join(data_dir, f"filtered_number_{i}.csv"))
    print(f"ğŸš€ æ­£åœ¨è™•ç†ï¼š{file_path}")
    
    # è®€å–è³‡æ–™
    df = pd.read_csv(file_path)

    # æ‹†åˆ†æ¬„ä½
    X_raw = df.iloc[:, 1:-1]  # å»æ‰ ID èˆ‡ é£†è‚¡
    y = df.iloc[:, -1]
    feature_names = X_raw.columns.tolist()

    # ç¼ºå€¼å¡«è£œï¼ˆä¸­ä½æ•¸ï¼‰
    imputer = SimpleImputer(strategy='median')
    X_imputed = imputer.fit_transform(X_raw)

    # å„²å­˜å¡«è£œç¼ºå€¼ä½†å°šæœªæ¨™æº–åŒ–çš„è³‡æ–™
    df_imputed = pd.DataFrame(X_imputed, columns=feature_names)
    df_imputed.insert(0, 'ID', df.iloc[:, 0])         # é‚„åŸ ID
    df_imputed['é£†è‚¡'] = y                            # é‚„åŸ target
    df_imputed.to_csv(os.path.join(imputed_dir, f"imputed_{i}.csv"), index=False)
    print(f"ğŸ“„ å·²å„²å­˜å¡«è£œç¼ºå€¼è³‡æ–™ï¼šimputed_{i}.csv")

    # æ¨™æº–åŒ–
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X_imputed)

    # Optuna èª¿åƒ
    def objective(trial):
        C = trial.suggest_loguniform('C', 1e-3, 1e2)
        penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])
        solver = 'liblinear' if penalty == 'l1' else 'lbfgs'
        model = LogisticRegression(C=C, penalty=penalty, solver=solver, max_iter=1000)
        score = cross_val_score(model, X_scaled, y, cv=3, scoring='f1').mean()
        return score

    study = optuna.create_study(direction="maximize")
    study.optimize(objective, n_trials=10)
    
    best_params = study.best_params
    print(f"âœ… æœ€ä½³åƒæ•¸ï¼š{best_params}")
    
    # è¨“ç·´æœ€ä½³æ¨¡å‹
    final_model = LogisticRegression(**best_params, solver='liblinear' if best_params['penalty'] == 'l1' else 'lbfgs', max_iter=1000)
    final_model.fit(X_scaled, y)

    # å–å¾—ç‰¹å¾µé‡è¦æ€§
    coef = final_model.coef_[0]
    feature_importance = {
        feature: float(np.abs(weight)) for feature, weight in zip(feature_names, coef)
    }

    # å„²å­˜æˆ JSON
    with open(os.path.join(output_dir, f"feature_importance_{i}.json"), "w", encoding="utf-8") as f:
        json.dump(feature_importance, f, ensure_ascii=False, indent=2)

    print(f"ğŸ“¦ å·²å„²å­˜ feature_importance_{i}.json\n")

print("ğŸ‰ å…¨éƒ¨è™•ç†å®Œæˆï¼")
